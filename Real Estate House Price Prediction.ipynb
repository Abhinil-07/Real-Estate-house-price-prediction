{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24befd87",
   "metadata": {},
   "source": [
    "## Real Estate House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9df16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "595b615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03091ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f008782",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b748b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f561eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "356e4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50,figsize =(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8467ee7",
   "metadata": {},
   "source": [
    "## Train - Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08091d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def split_train_test(data,test_ratio):\n",
    "#     shuffled = np.random.permutation(len(data))\n",
    "#     test_set_size = int(len(data) * test_ratio)\n",
    "#     test_indices = shuffled[:test_set_size]\n",
    "#     train_indices = shuffled[test_set_size: ]\n",
    "#     return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50df7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set,test_set = split_train_test(housing,0.2)\n",
    "# print (f\"Rows in train set :{len(train_set)}\\nRows in test set :{len(test_set)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e15c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set = train_test_split(housing,test_size=0.2,random_state=42)\n",
    "print (f\"Rows in train set :{len(train_set)}\\nRows in test set :{len(test_set)}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67f4868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_index,test_index in split.split(housing,housing['CHAS']):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5efe7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9a4c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1b2f1",
   "metadata": {},
   "source": [
    "## Looking for Correlations\n",
    "\n",
    "<!-- Correlation, statistical technique which determines how one variables moves/changes in relation with the other variable. It gives us the idea about the degree of the relationship of the two variables. It’s a bi-variate analysis measure which describes the association between different variables. In most of the business it’s useful to express one subject in terms of its relationship with others.It also helps us to find out whether the dataset provided to us is erroneous and also helps us to\n",
    "create new features by combining the existing features/label in the dataset that has been provided to us -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5fc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Correlation Matrix\n",
    "corr_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66c8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the correlation of the Label 'MEDV' wrt the other labels. A strong positive correlation as in case of RM means\n",
    "# increasing the value of RM also increases the value of MEDV and a strong negative correlation means the labels are inversly\n",
    "# proportional\n",
    "\n",
    "corr_matrix['MEDV'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3039974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"MEDV\",\"RM\",\"ZN\",\"LSTAT\"]\n",
    "scatter_matrix(housing[attributes],figsize = (12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3926e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that this graph has many outliers which can mislead our model. For ex a house with 5 rooms and one with 9 rooms have\n",
    "# the same price which is not possible.Also some points are way scattered.Thus plotting these graphs help us to clearly understand\n",
    "# the outliers and remove them that is basically clean the data\n",
    "\n",
    "housing.plot(kind =\"scatter\", x=\"RM\",y=\"MEDV\",alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfa87e",
   "metadata": {},
   "source": [
    "## Trying out Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105ec1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing [\"TAXRM\"] = housing[\"TAX\"]/housing[\"RM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f1a689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69540c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see a good negative correlation between our newly created attribute,TAXRM and MEDV\n",
    "\n",
    "housing.plot(kind =\"scatter\", x=\"TAXRM\",y=\"MEDV\",alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "607825f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"MEDV\",axis=1)\n",
    "housing_labels = strat_train_set[\"MEDV\"].copy\n",
    "housing_labels = np.array(housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a65d5a6",
   "metadata": {},
   "source": [
    "## Missing Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1e671",
   "metadata": {},
   "source": [
    "To take care of missing attributes we can do the following thing\n",
    "\n",
    "1. Get rid of the missing data points\n",
    "2. Get rid of the whole attribute\n",
    "3. Set the value to some value (0,median,or mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1ed7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 3 where we are calculating median\n",
    "#We will use the same median for our test set\n",
    "#because we are not sure that our test set does \n",
    "#not have missing values\n",
    "\n",
    "#We will also use this median in case some new\n",
    "#data is added to our dataset\n",
    "\n",
    "median = housing[\"RM\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c2dbc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"RM\"].fillna(median)\n",
    "#Note that the original housing dataframe will remain unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96ecc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc14518",
   "metadata": {},
   "source": [
    "This code creats an imputer object. It takes help of the SimpleImputer class and when we use the fit method it finds out the median for every attribute in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fcb3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = \"median\")\n",
    "imputer.fit(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0489c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381257b",
   "metadata": {},
   "source": [
    "We can see that it has calculated 15 medians that is median for every attribute in our dataset. Inspite of just needing the median for RM we are calculating all the medians because we want to create a pipeline that can handle missing values for other attributes also if present when more data will be added to our dataset in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d253501",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c91efb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X,columns = housing.columns)\n",
    "\n",
    "#We create a new dataset where the columns are taken from housing and the rows which have been \n",
    "#transformed are taken from X  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f1eba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686510a",
   "metadata": {},
   "source": [
    "## Scikit-Learn Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85b8a3",
   "metadata": {},
   "source": [
    "3 types primarily\n",
    "\n",
    "1. Estimators : Estimate some parameters based on a dataset. Eg: imputer It has a fit and transform method \n",
    "Fit method : Fits the dataset and calculates parameters according to the dataset\n",
    "\n",
    "2. Trasnformers : Takes input and returns output based on the learnings from fit(). It also has a convenience method called fit_transform() which fits and then transforms\n",
    "\n",
    "3. Predictors : Linear Regression model is an example of a predictor. Two common functions. Set(0 and Predict(). It also gives some score function which will evaluate the predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf115e4",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6683aec3",
   "metadata": {},
   "source": [
    "Primarily two types of feature scaling methods:\n",
    "\n",
    "1. Min-Max scaling (Normalization)\n",
    "       (value-min)/(max-min)\n",
    "       SK learn provides a class called MinMaxScaler for this\n",
    "       \n",
    "2. Standardization\n",
    "    (value - mean)/(Standard Deviation)\n",
    "    Sk learn provides a class called Standard Scalar for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce058b",
   "metadata": {},
   "source": [
    "## Creating a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18c413a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "my_pipeline =Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    #.... add as many tools as you want to\n",
    "    ('std_scaler',StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05ef1d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr = my_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1707fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr.shape\n",
    "#This is a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fbe495",
   "metadata": {},
   "source": [
    "## Selecting a desired model for our Real Estate House Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a04caa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(housing_num_tr, housing_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c90a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7f76cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_labels = housing_labels.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ff64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = my_pipeline.transform(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9195a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data =model.predict(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "986dbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(some_data)):\n",
    "    print(\"Actual value:\", some_labels[i], \"Predicted value:\", predicted_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b8fb4",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ac099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e807c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
